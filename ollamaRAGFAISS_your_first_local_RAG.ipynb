{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aac48844",
   "metadata": {},
   "source": [
    "# Your First Local RAG System: Efficiently Built Without External APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558c3a9f",
   "metadata": {},
   "source": [
    "Read article on [Medium](https://medium.com/@doyinelugbadebo/your-first-local-rag-system-de8302c7a676)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcb86923",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import libraries\n",
    "import fitz  # PyMuPDF\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Step 1: Extract Text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF file.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    return \" \".join([page.get_text(\"text\") for page in doc])\n",
    "\n",
    "pdf_path = \"Robust Weighted LAD Regression.pdf\"\n",
    "pdf_text = extract_text_from_pdf(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af422b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Split Text into Chunks\n",
    "def split_text_into_chunks(text, chunk_size=300):\n",
    "    \"\"\"\n",
    "    Splits the text into smaller chunks for embedding.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "chunks = split_text_into_chunks(pdf_text, chunk_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fc732c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Generate Embeddings and Create FAISS Index\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Efficient embedding model\n",
    "embeddings = embedding_model.encode(chunks)\n",
    "\n",
    "dimension = embeddings[0].shape[0]  # Vector dimension\n",
    "index = faiss.IndexFlatL2(dimension)  # L2 distance for similarity\n",
    "\n",
    "# Normalize embeddings for cosine similarity\n",
    "embeddings = np.array(embeddings)\n",
    "faiss.normalize_L2(embeddings)\n",
    "index.add(embeddings)\n",
    "\n",
    "# Metadata to map indices to chunks\n",
    "metadata = {i: chunks[i] for i in range(len(chunks))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c7218c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define a Function to Query the RAG System\n",
    "def query_rag_system(query, top_k=3):\n",
    "    \"\"\"\n",
    "    Queries the FAISS index with the input query and retrieves the top-k relevant chunks.\n",
    "    \"\"\"\n",
    "    query_embedding = embedding_model.encode([query])[0]\n",
    "    query_embedding = np.array([query_embedding])\n",
    "    faiss.normalize_L2(query_embedding)\n",
    "    \n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "    results = [metadata[idx] for idx in indices[0]]\n",
    "    return \"\\n\\n\".join(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35108fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Initialize ChatOllama for Chat-Style Responses\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2:latest\",\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "918285a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: RAG-Based Question Answering\n",
    "def ask_question(query):\n",
    "    \"\"\"\n",
    "    Processes a query using the RAG system and generates a response using ChatOllama.\n",
    "    \"\"\"\n",
    "    # Retrieve relevant context from the FAISS index\n",
    "    retrieved_context = query_rag_system(query, top_k=3)\n",
    "    \n",
    "    # Combine the context and query into a chat prompt\n",
    "    prompt = f\"\"\"Answer the following question based on the document context:\n",
    "    Context: {retrieved_context}\n",
    "    Query: {query}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get a response from ChatOllama\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ec65b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The document appears to be discussing the properties and behavior of the Least Absolute Deviation (LAD) regression estimator, specifically its robustness and asymptotic distribution under certain conditions. It discusses various aspects such as the breakdown point, finite sample breakdown point, and heteroscedasticity, and provides proofs and lemmas to support these claims. The document also presents an application to real datasets using the Weighted LAD (WLAD) estimator, which is a variant of the original LAD estimator.\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "query = \"What is the document about?\"\n",
    "response = ask_question(query)\n",
    "print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7814163",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
